{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dlwp_house_prices.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/irhallac/deep_learning_examples/blob/master/dlwp_house_prices.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "OLpxRzZG9wNT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jy13MUoxVTFN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.datasets import boston_housing\n",
        "\n",
        "(train_data, train_targets), (test_data, test_targets) =  boston_housing.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jkgL1Q2fVVbX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "b7dcb20a-8810-4fe9-aeaf-db6c8bd63e67"
      },
      "cell_type": "code",
      "source": [
        "print(train_data.shape)\n",
        "print(test_data.shape)\n",
        "print(train_targets)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(404, 13)\n",
            "(102, 13)\n",
            "[15.2 42.3 50.  21.1 17.7 18.5 11.3 15.6 15.6 14.4 12.1 17.9 23.1 19.9\n",
            " 15.7  8.8 50.  22.5 24.1 27.5 10.9 30.8 32.9 24.  18.5 13.3 22.9 34.7\n",
            " 16.6 17.5 22.3 16.1 14.9 23.1 34.9 25.  13.9 13.1 20.4 20.  15.2 24.7\n",
            " 22.2 16.7 12.7 15.6 18.4 21.  30.1 15.1 18.7  9.6 31.5 24.8 19.1 22.\n",
            " 14.5 11.  32.  29.4 20.3 24.4 14.6 19.5 14.1 14.3 15.6 10.5  6.3 19.3\n",
            " 19.3 13.4 36.4 17.8 13.5 16.5  8.3 14.3 16.  13.4 28.6 43.5 20.2 22.\n",
            " 23.  20.7 12.5 48.5 14.6 13.4 23.7 50.  21.7 39.8 38.7 22.2 34.9 22.5\n",
            " 31.1 28.7 46.  41.7 21.  26.6 15.  24.4 13.3 21.2 11.7 21.7 19.4 50.\n",
            " 22.8 19.7 24.7 36.2 14.2 18.9 18.3 20.6 24.6 18.2  8.7 44.  10.4 13.2\n",
            " 21.2 37.  30.7 22.9 20.  19.3 31.7 32.  23.1 18.8 10.9 50.  19.6  5.\n",
            " 14.4 19.8 13.8 19.6 23.9 24.5 25.  19.9 17.2 24.6 13.5 26.6 21.4 11.9\n",
            " 22.6 19.6  8.5 23.7 23.1 22.4 20.5 23.6 18.4 35.2 23.1 27.9 20.6 23.7\n",
            " 28.  13.6 27.1 23.6 20.6 18.2 21.7 17.1  8.4 25.3 13.8 22.2 18.4 20.7\n",
            " 31.6 30.5 20.3  8.8 19.2 19.4 23.1 23.  14.8 48.8 22.6 33.4 21.1 13.6\n",
            " 32.2 13.1 23.4 18.9 23.9 11.8 23.3 22.8 19.6 16.7 13.4 22.2 20.4 21.8\n",
            " 26.4 14.9 24.1 23.8 12.3 29.1 21.  19.5 23.3 23.8 17.8 11.5 21.7 19.9\n",
            " 25.  33.4 28.5 21.4 24.3 27.5 33.1 16.2 23.3 48.3 22.9 22.8 13.1 12.7\n",
            " 22.6 15.  15.3 10.5 24.  18.5 21.7 19.5 33.2 23.2  5.  19.1 12.7 22.3\n",
            " 10.2 13.9 16.3 17.  20.1 29.9 17.2 37.3 45.4 17.8 23.2 29.  22.  18.\n",
            " 17.4 34.6 20.1 25.  15.6 24.8 28.2 21.2 21.4 23.8 31.  26.2 17.4 37.9\n",
            " 17.5 20.   8.3 23.9  8.4 13.8  7.2 11.7 17.1 21.6 50.  16.1 20.4 20.6\n",
            " 21.4 20.6 36.5  8.5 24.8 10.8 21.9 17.3 18.9 36.2 14.9 18.2 33.3 21.8\n",
            " 19.7 31.6 24.8 19.4 22.8  7.5 44.8 16.8 18.7 50.  50.  19.5 20.1 50.\n",
            " 17.2 20.8 19.3 41.3 20.4 20.5 13.8 16.5 23.9 20.6 31.5 23.3 16.8 14.\n",
            " 33.8 36.1 12.8 18.3 18.7 19.1 29.  30.1 50.  50.  22.  11.9 37.6 50.\n",
            " 22.7 20.8 23.5 27.9 50.  19.3 23.9 22.6 15.2 21.7 19.2 43.8 20.3 33.2\n",
            " 19.9 22.5 32.7 22.  17.1 19.  15.  16.1 25.1 23.7 28.7 37.2 22.6 16.4\n",
            " 25.  29.8 22.1 17.4 18.1 30.3 17.5 24.7 12.6 26.5 28.7 13.3 10.4 24.4\n",
            " 23.  20.  17.8  7.  11.8 24.4 13.8 19.4 25.2 19.4 19.4 29.1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uFoUh95xV554",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "989397e2-cbee-4769-958f-ccc0848f09e6"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "mean = train_data.mean(axis=0)\n",
        "print(mean)\n",
        "train_data -= mean\n",
        "std = train_data.std(axis=0)\n",
        "print(std)\n",
        "train_data /= std\n",
        "\n",
        "test_data -= mean\n",
        "test_data /= std"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3.74511057e+00 1.14801980e+01 1.11044307e+01 6.18811881e-02\n",
            " 5.57355941e-01 6.26708168e+00 6.90106436e+01 3.74027079e+00\n",
            " 9.44059406e+00 4.05898515e+02 1.84759901e+01 3.54783168e+02\n",
            " 1.27408168e+01]\n",
            "[9.22929073e+00 2.37382770e+01 6.80287253e+00 2.40939633e-01\n",
            " 1.17147847e-01 7.08908627e-01 2.79060634e+01 2.02770050e+00\n",
            " 8.68758849e+00 1.66168506e+02 2.19765689e+00 9.39946015e+01\n",
            " 7.24556085e+00]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EqOp-d00WHKP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "63d878b7-2330-4766-d800-9a2f8cadbb3e"
      },
      "cell_type": "code",
      "source": [
        "print(test_data)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1.55369355 -0.48361547  1.0283258  ...  0.78447637 -3.48459553\n",
            "   2.25092074]\n",
            " [-0.39242675 -0.48361547 -0.16087773 ... -0.30759583  0.42733126\n",
            "   0.47880119]\n",
            " [-0.39982927 -0.48361547 -0.86940196 ...  0.78447637  0.44807713\n",
            "  -0.41415936]\n",
            " ...\n",
            " [-0.20709507 -0.48361547  1.24588095 ... -1.71818909  0.37051949\n",
            "  -1.49344089]\n",
            " [-0.36698601 -0.48361547 -0.72093526 ... -0.48960787  0.39275481\n",
            "  -0.41829982]\n",
            " [-0.0889679  -0.48361547  1.24588095 ... -1.71818909 -1.21946544\n",
            "  -0.40449827]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PHOaVxdMX8Ix",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "def build_model():\n",
        "    # Because we will need to instantiate\n",
        "    # the same model multiple times,\n",
        "    # we use a function to construct it.\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.Dense(64, activation='relu',\n",
        "                           input_shape=(train_data.shape[1],)))\n",
        "    model.add(layers.Dense(64, activation='relu'))\n",
        "    model.add(layers.Dense(1))\n",
        "    model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I9lLFS1nYLcE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "5cf716fd-2732-4a31-fe2d-d4ae5f0f8a76"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "k = 4\n",
        "num_val_samples = len(train_data) // k\n",
        "print(\"num_val_samples {}\".format(num_val_samples))\n",
        "num_epochs = 100\n",
        "all_scores = []\n",
        "for i in range(k):\n",
        "    print('processing fold #', i)\n",
        "    # Prepare the validation data: data from partition # k\n",
        "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "    # Prepare the training data: data from all other partitions\n",
        "    partial_train_data = np.concatenate(\n",
        "        [train_data[:i * num_val_samples],\n",
        "         train_data[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [train_targets[:i * num_val_samples],\n",
        "         train_targets[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "\n",
        "    # Build the Keras model (already compiled)\n",
        "    model = build_model()\n",
        "    # Train the model (in silent mode, verbose=0)\n",
        "    model.fit(partial_train_data, partial_train_targets,\n",
        "              epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    # Evaluate the model on the validation data\n",
        "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
        "    all_scores.append(val_mae)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num_val_samples 101\n",
            "('processing fold #', 0)\n",
            "('processing fold #', 1)\n",
            "('processing fold #', 2)\n",
            "('processing fold #', 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DUTxTYDpYteS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "409e59ed-0284-458a-cec9-4780fc77aa40"
      },
      "cell_type": "code",
      "source": [
        "print(all_scores)\n",
        "np.mean(all_scores)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2.0581326413862775, 2.2001309324019025, 2.8750618802438868, 2.410775157484678]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.386025152879186"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "5klAy00bY7sB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "\n",
        "# Some memory clean-up\n",
        "K.clear_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fgkCa7KkY8Xi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0b372abf-2bf7-48c8-d057-7b912717d9ae"
      },
      "cell_type": "code",
      "source": [
        "num_epochs = 500\n",
        "all_mae_histories = []\n",
        "for i in range(k):\n",
        "    print('processing fold #', i)\n",
        "    # Prepare the validation data: data from partition # k\n",
        "    val_data = train_data[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "    val_targets = train_targets[i * num_val_samples: (i + 1) * num_val_samples]\n",
        "\n",
        "    # Prepare the training data: data from all other partitions\n",
        "    partial_train_data = np.concatenate(\n",
        "        [train_data[:i * num_val_samples],\n",
        "         train_data[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "    partial_train_targets = np.concatenate(\n",
        "        [train_targets[:i * num_val_samples],\n",
        "         train_targets[(i + 1) * num_val_samples:]],\n",
        "        axis=0)\n",
        "\n",
        "    # Build the Keras model (already compiled)\n",
        "    model = build_model()\n",
        "    # Train the model (in silent mode, verbose=0)\n",
        "    history = model.fit(partial_train_data, partial_train_targets,\n",
        "                        validation_data=(val_data, val_targets),\n",
        "                        epochs=num_epochs, batch_size=1, verbose=0)\n",
        "    mae_history = history.history['val_mean_absolute_error']\n",
        "    all_mae_histories.append(mae_history)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('processing fold #', 0)\n",
            "('processing fold #', 1)\n",
            "('processing fold #', 2)\n",
            "('processing fold #', 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p2Bv_yMSZHF5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "average_mae_history = [\n",
        "    np.mean([x[i] for x in all_mae_histories]) for i in range(num_epochs)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I7vf1Ur6ZJto",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(1, len(average_mae_history) + 1), average_mae_history)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b4lqXdtjZZ_4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def smooth_curve(points, factor=0.9):\n",
        "  smoothed_points = []\n",
        "  for point in points:\n",
        "    if smoothed_points:\n",
        "      previous = smoothed_points[-1]\n",
        "      smoothed_points.append(previous * factor + point * (1 - factor))\n",
        "    else:\n",
        "      smoothed_points.append(point)\n",
        "  return smoothed_points\n",
        "\n",
        "smooth_mae_history = smooth_curve(average_mae_history[10:])\n",
        "\n",
        "plt.plot(range(1, len(smooth_mae_history) + 1), smooth_mae_history)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Validation MAE')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sNJFC91UZfOt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "According to this plot, it seems that validation MAE stops improving significantly after 80 epochs. Past that point, we start overfitting.\n",
        "\n",
        "Once we are done tuning other parameters of our model (besides the number of epochs, we could also adjust the size of the hidden layers), we can train a final \"production\" model on all of the training data, with the best parameters, then look at its performance on the test data:"
      ]
    },
    {
      "metadata": {
        "id": "RILtgOcXZgK6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get a fresh, compiled model.\n",
        "model = build_model()\n",
        "# Train it on the entirety of the data.\n",
        "model.fit(train_data, train_targets,\n",
        "          epochs=80, batch_size=16, verbose=0)\n",
        "test_mse_score, test_mae_score = model.evaluate(test_data, test_targets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QrrxZcNXZkoD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "test_mae_score"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}